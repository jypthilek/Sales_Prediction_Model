{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\sjyot\\\\Downloads\\\\train.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\sjyot\\\\Downloads\\\\test.csv\")\n"
   ],
   "id": "aaa954101ba2fec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_data['source'] = 'train'\n",
    "test_data['source'] = 'test'"
   ],
   "id": "8af92e50bec32356",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data = pd.concat([train_data, test_data], ignore_index=True)",
   "id": "ecf07b0289b17338",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(train_data.head(5))",
   "id": "f13cb134cbc2a5ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(test_data.head())",
   "id": "f87b48397c003afb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(test_data.shape, train_data.shape, combined_data.shape)",
   "id": "f65f4a76cbdef561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.describe()",
   "id": "f5b2ca5243fd00d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.apply(lambda x: len(x.unique()))\n",
   "id": "2de6b63124154468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical_columns = [x for x in combined_data.dtypes.index if combined_data.dtypes[x]=='object']\n",
    "categorical_columns = [x for x in categorical_columns if x not in ['Item_Identifier','Outlet_Identifier','source']]\n",
    "print(categorical_columns)"
   ],
   "id": "365eaf14961fe286",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for column in categorical_columns:\n",
    "\n",
    "    print(combined_data[column].value_counts())"
   ],
   "id": "ad11d3def44f437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_with_nulls = combined_data.columns[combined_data.isnull().any()]\n",
    "columns_with_nulls"
   ],
   "id": "f54fbe3b32d0b524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "item_avg_weight = (\n",
    "    combined_data\n",
    "    .pivot_table(values='Item_Weight', index='Item_Identifier')\n",
    "    ['Item_Weight']\n",
    ")\n",
    "item_avg_weight"
   ],
   "id": "fcff95b0ebf385fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "miss_bool = combined_data['Item_Weight'].isnull()\n",
    "\n",
    "#Impute data and check #missing values before and after imputation to confirm\n",
    "print('Orignal #missing: %d'% sum(miss_bool))\n",
    "miss_bool\n"
   ],
   "id": "7859aa24568109c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#item_avg_weight.loc[x, 'Item_Weight']\n",
    "combined_data.loc[miss_bool, 'Item_Weight'] = (\n",
    "    combined_data.loc[miss_bool, 'Item_Identifier'].map(item_avg_weight)\n",
    ")\n"
   ],
   "id": "3b69b85926ec329a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data",
   "id": "148923e2657509f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "miss_bool = combined_data['Item_Weight'].isnull()\n",
    "\n",
    "#Impute data and check #missing values before and after imputation to confirm\n",
    "print('Orignal #missing: %d'% sum(miss_bool))\n",
    "miss_bool"
   ],
   "id": "f7f07ef3605ba925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.pivot_table(values='Item_Outlet_Sales',index='Outlet_Type')\n",
   "id": "47aec4cd15605828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Determine average visibility of a product\n",
    "#visibility_avg = combined_data.pivot_table(values='Item_Visibility', index='Item_Identifier')\n",
    "visibility_avg = (\n",
    "    combined_data.pivot_table(values='Item_Visibility', index='Item_Identifier')\n",
    "    ['Item_Visibility']\n",
    ")\n",
    "#Impute 0 values with mean visibility of that product:\n",
    "miss_bool = (combined_data['Item_Visibility'] == 0)\n",
    "\n",
    "print ('Number of 0 values initially: %d'%sum(miss_bool))\n"
   ],
   "id": "3727b6e53361e078",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_data.loc[miss_bool,'Item_Visibility'] = combined_data.loc[miss_bool,'Item_Identifier'].map(visibility_avg)\n",
    "print ('Number of 0 values after modification: %d'%sum(combined_data['Item_Visibility'] == 0))"
   ],
   "id": "d751e5790feaee90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_data['Item_Type_Redefined'] = combined_data['Item_Identifier'].apply(lambda x: x[0:2])\n",
    "#Rename them to more intuitive categories:\n",
    "combined_data['Item_Type_Redefined'] = combined_data['Item_Type_Redefined'].map({'FD':'Food',\n",
    "                                                             'NC':'Non-Consumable',\n",
    "                                                             'DR':'Drinks'})\n",
    "combined_data['Item_Type_Redefined'].value_counts()\n"
   ],
   "id": "a30f59a4d8335946",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_data['Item_Fat_Content'] = np.where(\n",
    "    combined_data['Item_Type_Redefined'].eq(\"Non-Consumable\"),\n",
    "    \"Non-Edible\",\n",
    "    combined_data['Item_Fat_Content']\n",
    ")\n",
    "combined_data['Item_Fat_Content'].value_counts()"
   ],
   "id": "8626f54b561d3ecf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Merging similar fat content items Low Fat, LF low_fat\n",
    "print(combined_data['Item_Fat_Content'].value_counts())\n",
    "\n",
    "print ('\\nModified Categories:')\n",
    "combined_data['Item_Fat_Content'] = combined_data['Item_Fat_Content'].replace({'LF':'Low Fat',\n",
    "                                                             'reg':'Regular',\n",
    "                                                             'low fat':'Low Fat'})\n",
    "print (combined_data['Item_Fat_Content'].value_counts())"
   ],
   "id": "39ba291f9de312be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#years of operation of a store\n",
    "combined_data['Outlet_Years_Operation'] = 2013 - combined_data['Outlet_Establishment_Year']\n",
    "combined_data['Outlet_Years_Operation'].describe()\n"
   ],
   "id": "4b25899cbdea1aaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode Outlet separately\n",
    "combined_data['Outlet'] = LabelEncoder().fit_transform(combined_data['Outlet_Identifier'])\n",
    "\n",
    "# Columns to encode\n",
    "var_mod = [\n",
    "    'Item_Fat_Content', 'Outlet_Location_Type', 'Outlet_Size',\n",
    "    'Item_Type_Redefined', 'Outlet_Type', 'Outlet'\n",
    "]\n",
    "\n",
    "# Fit separate encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "for col in var_mod:\n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_data[col] = label_encoder.fit_transform(combined_data[col])\n",
    "    label_encoders[col] = label_encoder    # store encoder if needed later\n"
   ],
   "id": "8c771a94ac7af356",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Columns to one-hot encode\n",
    "cols_to_encode = [\n",
    "    'Item_Fat_Content',\n",
    "    'Outlet_Location_Type',\n",
    "    'Outlet_Size',\n",
    "    'Outlet_Type',\n",
    "    'Item_Type_Redefined',\n",
    "    'Outlet'\n",
    "]\n",
    "\n",
    "# Apply one-hot encoding\n",
    "combined_data = pd.get_dummies(combined_data, columns=cols_to_encode, drop_first=True)\n"
   ],
   "id": "3746cca5a48e63e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.dtypes",
   "id": "7a61d2422a115bac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.head(5)",
   "id": "8d960366a3149d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.columns",
   "id": "8ab00c213ae1208c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop unused columns\n",
    "columns_to_drop = ['Item_Type','Outlet_Establishment_Year', 'Item_Identifier','Outlet_Identifier']\n",
    "combined_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "#combined_data.drop(columns=columns_to_drop, inplace=True, axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "train = combined_data[combined_data['source'] == \"train\"].copy()\n",
    "test = combined_data[combined_data['source'] == \"test\"].copy()\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "train.drop(columns=['source'], inplace=True)\n",
    "\n",
    "# 'Item_Outlet_Sales' exists only in train, so drop safely only if present\n",
    "test.drop(columns=['Item_Outlet_Sales', 'source'], errors='ignore', inplace=True)\n",
    "\n",
    "# Export cleaned datasets\n",
    "train.to_csv(\"train_modified.csv\", index=False)\n",
    "test.to_csv(\"test_modified.csv\", index=False)\n"
   ],
   "id": "7e63a98da8b3b675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_data.isna().sum()",
   "id": "43b2735a674c5c6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from itertools import product\n"
   ],
   "id": "fd4da96ba46c9c44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Load train and test date\n",
    "train = pd.read_csv(\"train_modified.csv\")\n",
    "test = pd.read_csv(\"test_modified.csv\")\n",
    "test_copy = test_data.copy()"
   ],
   "id": "560e4c3289e991a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train split\n",
    "X_train = train.drop(\"Item_Outlet_Sales\", axis=1)\n",
    "y_train = test[\"Item_Outlet_Sales\"]\n",
    "X_test = test.drop(\"Item_Outlet_Sales\", axis=1)\n",
    "y_test = train[\"Item_Outlet_Sales\"]\n",
    "\n",
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Test Shape :\", test.shape)\n"
   ],
   "id": "1561b1a62617d6b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Finalizing Hyper parameter (learning rate, tree depth and iterations\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.05, 0.03, 0.02],\n",
    "    \"depth\": [4, 6, 8,9],\n",
    "    \"iterations\": [800, 500, 1500,700]\n",
    "}"
   ],
   "id": "6acf5c448c8ee16d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tune_catboost(X, y, param_grid):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "\n",
    "    for lr, depth, iters in product(\n",
    "        param_grid[\"learning_rate\"],\n",
    "        param_grid[\"depth\"],\n",
    "        param_grid[\"iterations\"]\n",
    "    ):\n",
    "        rmse_scores = []\n",
    "\n",
    "        print(f\"Testing: LR={lr}, Depth={depth}, Iter={iters}\")\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = CatBoostRegressor(\n",
    "                learning_rate=lr,\n",
    "                depth=depth,\n",
    "                iterations=iters,\n",
    "                loss_function='RMSE',\n",
    "                verbose=False,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "            rmse_scores.append(rmse)\n",
    "\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        results.append((avg_rmse, lr, depth, iters))\n",
    "\n",
    "        print(f\"   ‚Üí Avg RMSE: {avg_rmse:.2f}\\n\")\n",
    "\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    best_rmse, best_lr, best_depth, best_iters = results[0]\n",
    "\n",
    "    print(\"\\nüèÜ BEST PARAMETERS\")\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Learning Rate : {best_lr}\")\n",
    "    print(f\"Depth         : {best_depth}\")\n",
    "    print(f\"Iterations    : {best_iters}\")\n",
    "    print(f\"CV RMSE       : {best_rmse:.2f}\")\n",
    "\n",
    "    return best_lr, best_depth, best_iters"
   ],
   "id": "3d71fb53654d2a9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "best_lr, best_depth, best_iters = tune_catboost(X_train, y_train, param_grid)\n",
    "\n",
    "#Model Training\n",
    "final_model = CatBoostRegressor(\n",
    "    learning_rate=best_lr,\n",
    "    depth=best_depth,\n",
    "    iterations=best_iters,\n",
    "    loss_function='RMSE',\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training final CatBoost model on FULL DATA...\\n\")\n",
    "final_model.fit(X_train, y_train)"
   ],
   "id": "35690eb1be76f2f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # Model Testing\n",
    "test_predictions = final_model.predict(test)\n",
    "test_predictions = np.maximum(test_predictions, 0)\n",
    "#final_submission = test_copy[[\"Item_Identifier\", \"Outlet_Identifier\"]]\n",
    "#final_submission[[\"Outlet_Identifier\"]] = test_predictions\n",
    "final_submission = pd.DataFrame()\n",
    "final_submission[\"Item_Identifier\"] = test_copy[\"Item_Identifier\"]\n",
    "final_submission[\"Outlet_Identifier\"] = test_copy[\"Outlet_Identifier\"]\n",
    "final_submission[\"Item_Outlet_Sales\"] = test_predictions\n",
    "\n",
    "\n",
    "#test[\"Item_Outlet_Sales\"] = test_predictions\n",
    "\n",
    "final_submission.to_csv(\"final_result_submission.csv\", index=False)\n",
    "print(\"\\nüìÅ Saved: final_submission.csv\")"
   ],
   "id": "78c4a2623b105c27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_copy.shape",
   "id": "ed31dd519ccef8ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# 8. Report Training Metrics on FULL DATA\n",
    "# ================================================================\n",
    "train_preds = final_model.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "r2 = r2_score(y_train, train_preds)\n",
    "mae = mean_absolute_error(y_train, train_preds)\n",
    "mape = np.mean(np.abs((y_train - train_preds) / y_train)) * 100\n",
    "\n",
    "print(\"\\n========== FINAL MODEL METRICS (Train Data) ==========\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R¬≤   : {r2:.4f}\")\n",
    "print(f\"MAE  : {mae:.2f}\")\n",
    "print(f\"MAPE : {mape:.2f}%\")\n",
    "print(\"======================================================\")"
   ],
   "id": "ccadadf0026b1ac1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =======================\n",
    "# 8. Evaluate on TRAIN Data\n",
    "# =======================\n",
    "train_preds = final_model.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "train_mae = mean_absolute_error(y_train, train_preds)\n",
    "train_mape = np.mean(np.abs((y_train - train_preds) / y_train)) * 100\n",
    "\n",
    "\n",
    "#Model Evaluation\n",
    "test_preds = final_model.predict(X_test)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "test_mape = np.mean(np.abs((y_test - test_preds) / y_test)) * 100\n",
    "\n",
    "print(\"\\n========== FINAL MODEL METRICS (TEST DATA) ==========\")\n",
    "print(f\"RMSE : {test_rmse:.2f}\")\n",
    "print(f\"R¬≤   : {test_r2:.4f}\")\n",
    "print(f\"MAE  : {test_mae:.2f}\")\n",
    "print(f\"MAPE : {test_mape:.2f}%\")\n",
    "print(\"======================================================\")"
   ],
   "id": "1a34db36ced08a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4aee8402cab5b850",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c0987dd7f47ee442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3472583f9cfbffee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b1495dbc41427f27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aba2880c2b7afab0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a848edfb57988645",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2371966f446777a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f7be79c418e3c90a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb2c19ed9a454f3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "30f501ea15b7e141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7c584dcf95b7556f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
